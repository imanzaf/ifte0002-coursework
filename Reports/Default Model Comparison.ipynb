{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92b2ca06-05fd-42ac-a232-96d7c1550368",
   "metadata": {},
   "source": [
    "# Table of Model Evaluation Metric Comparisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "385429cd-c0a4-4644-90f4-70610a7deab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (Class 1)</th>\n",
       "      <th>Recall (Class 1)</th>\n",
       "      <th>F1 Score (Class 1)</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN (Thresh 0.40)</td>\n",
       "      <td>0.6370</td>\n",
       "      <td>0.3480</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.4880</td>\n",
       "      <td>0.7750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGB (Thresh 0.30)</td>\n",
       "      <td>0.6607</td>\n",
       "      <td>0.2626</td>\n",
       "      <td>0.9256</td>\n",
       "      <td>0.4091</td>\n",
       "      <td>0.7317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB (Thresh 0.50)</td>\n",
       "      <td>0.6607</td>\n",
       "      <td>0.3463</td>\n",
       "      <td>0.6815</td>\n",
       "      <td>0.4592</td>\n",
       "      <td>0.7317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB (Thresh 0.70)</td>\n",
       "      <td>0.6607</td>\n",
       "      <td>0.4886</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.3610</td>\n",
       "      <td>0.7317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF (Baseline)</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.7760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF (Class Weighted)</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.5900</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.7790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF (Thresh 0.2)</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.7790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF Weighted + Thresh 0.2</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.7790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Accuracy  Precision (Class 1)  Recall (Class 1)  \\\n",
       "0         ANN (Thresh 0.40)    0.6370               0.3480            0.8160   \n",
       "1         XGB (Thresh 0.30)    0.6607               0.2626            0.9256   \n",
       "2         XGB (Thresh 0.50)    0.6607               0.3463            0.6815   \n",
       "3         XGB (Thresh 0.70)    0.6607               0.4886            0.2862   \n",
       "4             RF (Baseline)    0.8030               0.5800            0.1700   \n",
       "5       RF (Class Weighted)    0.8020               0.5900            0.1500   \n",
       "6           RF (Thresh 0.2)    0.8020               0.3400            0.8100   \n",
       "7  RF Weighted + Thresh 0.2    0.8020               0.3500            0.7900   \n",
       "\n",
       "   F1 Score (Class 1)  ROC AUC  \n",
       "0              0.4880   0.7750  \n",
       "1              0.4091   0.7317  \n",
       "2              0.4592   0.7317  \n",
       "3              0.3610   0.7317  \n",
       "4              0.2600   0.7760  \n",
       "5              0.2400   0.7790  \n",
       "6              0.4800   0.7790  \n",
       "7              0.4900   0.7790  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "data = {\n",
    "    \"Model\": [\n",
    "        \"ANN (Thresh 0.40)\",\n",
    "        \"XGB (Thresh 0.30)\",\n",
    "        \"XGB (Thresh 0.50)\",\n",
    "        \"XGB (Thresh 0.70)\",\n",
    "        \"RF (Baseline)\",\n",
    "        \"RF (Class Weighted)\",\n",
    "        \"RF (Thresh 0.2)\",\n",
    "        \"RF Weighted + Thresh 0.2\"\n",
    "    ],\n",
    "    \"Accuracy\": [0.637, 0.6607, 0.6607, 0.6607, 0.803, 0.802, 0.802, 0.802],\n",
    "    \"Precision (Class 1)\": [0.348, 0.2626, 0.3463, 0.4886, 0.58, 0.59, 0.34, 0.35],\n",
    "    \"Recall (Class 1)\": [0.816, 0.9256, 0.6815, 0.2862, 0.17, 0.15, 0.81, 0.79],\n",
    "    \"F1 Score (Class 1)\": [0.488, 0.4091, 0.4592, 0.3610, 0.26, 0.24, 0.48, 0.49],\n",
    "    \"ROC AUC\": [0.775, 0.7317, 0.7317, 0.7317, 0.776, 0.779, 0.779, 0.779]\n",
    "}\n",
    "\n",
    "el_comparison_df = pd.DataFrame(data)\n",
    "model_comparison_df = model_comparison_df.round(4)\n",
    "display(model_comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c346250f-6efc-46c1-a373-0afd694cc343",
   "metadata": {},
   "source": [
    "# Detailed Comparative Analysis of ANN, XGBoost, and Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737373f4-863b-4a94-b7fd-4cb34a4638a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ANN\n",
    "\n",
    "**Strengths:**\n",
    "- Strong recall, which is vital in high-risk settings (e.g., catching defaulters).\n",
    "- Balanced F1 score, meaning good trade-off between precision and recall.\n",
    "- High AUC, indicating good overall discriminatory power.\n",
    "\n",
    "**Limitations:**\n",
    "- Lower precision than threshold-tuned Random Forest or XGBoost at 0.7, meaning more false positives.\n",
    "- Lowest accuracy among tested models.\n",
    "\n",
    "\n",
    "### XGBoost\n",
    "\n",
    "**Insights:**\n",
    "- At threshold 0.30, XGBoost delivers the highest recall (92.56%), but sacrifices precision heavily — useful when missing a defaulter is more costly than a false alarm.\n",
    "- At threshold 0.50, it achieves the best balance between recall and precision, yielding a competitive F1 score (0.4592).\n",
    "- At threshold 0.70, XGBoost becomes precision-focused, identifying fewer positives but with high accuracy — suited to false-positive-sensitive applications.\n",
    "\n",
    "**Overall:**\n",
    "- Flexible model when paired with threshold tuning.\n",
    "- Slightly lower AUC than ANN and Random Forest, suggesting marginally weaker ranking performance.\n",
    "\n",
    "\n",
    "### Random Forest (RF)\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Baseline RF is biased toward the majority class (class 0), with poor recall (0.17).\n",
    "- Class weighting alone does not significantly improve recall, indicating that rebalancing class importance isn't sufficient on its own.\n",
    "- Threshold tuning drastically improves recall to 0.81, and F1 to 0.48.\n",
    "- The best RF configuration is class weighting + threshold tuning, achieving the highest F1 score (0.49) among all models and competitive recall and precision.\n",
    "\n",
    "**AUC**: Highest among all models (tied with ANN), confirming strong overall discrimination ability.\n",
    "\n",
    "### Three Model Analysis\n",
    "\n",
    "- **ANN** is a strong contender for balanced, recall-oriented classification, offering consistent performance and a high AUC.\n",
    "- **XGBoost** is highly flexible, allowing precise control over the trade-off between recall and precision depending on threshold selection.\n",
    "- **Random Forest**, when combined with class weighting and threshold tuning, emerges as the most balanced and reliable model, particularly when the F1 score is the primary concern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5a12c8-d4e0-4ee3-9369-dfd31817b6ad",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a22419-baa0-48b9-8fa4-4c597c2582ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "In the context of this coursework — developing a model to minimise default risk in a loan dataset — the evaluation reveals that no single model is universally optimal. However, the priority in credit risk modelling is to identify defaulters as accurately as possible, even at the cost of increased false positives, because the financial cost of undetected defaults far outweighs that of overly cautious lending.\n",
    "\n",
    "\n",
    "- **XGBoost** with a lowered decision threshold (0.30) achieves the highest recall (0.9256), making it the most effective model for flagging high-risk borrowers and minimising missed defaults. This makes it highly suitable in settings where risk aversion is paramount, such as subprime or unsecured lending.\n",
    "\n",
    "- **Random Forest**, with class weighting and threshold tuning (0.2), offers the best overall F1 score (0.49), combining strong recall (0.79) with better precision than XGBoost. This makes it an excellent choice for balanced decision-making, where lenders aim to reduce default while maintaining acceptable approval rates.\n",
    "\n",
    "- **ANN**, while slightly weaker in AUC and precision, still performs competitively with recall of 0.816 and a strong F1 score of 0.488, offering a more interpretable and stable alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcb1afb-2102-4c9d-aa01-912fd10e0e39",
   "metadata": {},
   "source": [
    "# Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05797978-2416-4803-b7c0-f6fb7cd69acf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "To meet the coursework objective of minimising default**, XGBoost (threshold 0.30) is the most suitable primary model. However, to ensure operational balance and reduce unnecessary loan rejections, it may be advisable to pair it with a Random Forest model in a dual-stage system, or use business-defined thresholds to modulate risk appetite over time.\n",
    "\n",
    "This approach not only optimises for technical accuracy, but also aligns with the practical and regulatory demands of credit risk management."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a39462-8c10-4d71-8859-1c7b6c65f468",
   "metadata": {},
   "source": [
    "# Model Recommendation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3555672b-54be-433b-87b2-916e2cac9d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_cb3d5_row0_col0, #T_cb3d5_row0_col1, #T_cb3d5_row0_col2, #T_cb3d5_row1_col0, #T_cb3d5_row1_col1, #T_cb3d5_row1_col2, #T_cb3d5_row2_col0, #T_cb3d5_row2_col1, #T_cb3d5_row2_col2, #T_cb3d5_row3_col0, #T_cb3d5_row3_col1, #T_cb3d5_row3_col2 {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 300px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_cb3d5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_cb3d5_level0_col0\" class=\"col_heading level0 col0\" >Goal</th>\n",
       "      <th id=\"T_cb3d5_level0_col1\" class=\"col_heading level0 col1\" >Best Model</th>\n",
       "      <th id=\"T_cb3d5_level0_col2\" class=\"col_heading level0 col2\" >Reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cb3d5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_cb3d5_row0_col0\" class=\"data row0 col0\" >Maximizing Recall</td>\n",
       "      <td id=\"T_cb3d5_row0_col1\" class=\"data row0 col1\" >XGBoost @ Threshold 0.30</td>\n",
       "      <td id=\"T_cb3d5_row0_col2\" class=\"data row0 col2\" >Catching nearly all positives (recall = 0.93)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cb3d5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_cb3d5_row1_col0\" class=\"data row1 col0\" >Maximizing Precision</td>\n",
       "      <td id=\"T_cb3d5_row1_col1\" class=\"data row1 col1\" >XGBoost @ Threshold 0.70</td>\n",
       "      <td id=\"T_cb3d5_row1_col2\" class=\"data row1 col2\" >Highest precision (0.49) with controlled recall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cb3d5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_cb3d5_row2_col0\" class=\"data row2 col0\" >Balanced F1 (Fair Trade-off)</td>\n",
       "      <td id=\"T_cb3d5_row2_col1\" class=\"data row2 col1\" >RF Weighted + Threshold</td>\n",
       "      <td id=\"T_cb3d5_row2_col2\" class=\"data row2 col2\" >Best F1 (0.49), strong recall and decent precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cb3d5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_cb3d5_row3_col0\" class=\"data row3 col0\" >Overall AUC Performance</td>\n",
       "      <td id=\"T_cb3d5_row3_col1\" class=\"data row3 col1\" >ANN or RF (any tuned)</td>\n",
       "      <td id=\"T_cb3d5_row3_col2\" class=\"data row3 col2\" >AUC (0.775–0.779), best class discrimination</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f2410fcd70>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "model_recommendation_data = {\n",
    "    \"Goal\": [\n",
    "        \"Maximizing Recall\",\n",
    "        \"Maximizing Precision\",\n",
    "        \"Balanced F1 (Fair Trade-off)\",\n",
    "        \"Overall AUC Performance\"\n",
    "    ],\n",
    "    \"Best Model\": [\n",
    "        \"XGBoost @ Threshold 0.30\",\n",
    "        \"XGBoost @ Threshold 0.70\",\n",
    "        \"RF Weighted + Threshold\",\n",
    "        \"ANN or RF (any tuned)\"\n",
    "    ],\n",
    "    \"Reasoning\": [\n",
    "        \"Catching nearly all positives (recall = 0.93)\",\n",
    "        \"Highest precision (0.49) with controlled recall\",\n",
    "        \"Best F1 (0.49), strong recall and decent precision\",\n",
    "        \"AUC (0.775–0.779), best class discrimination\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "model_recommendation_df = pd.DataFrame(model_recommendation_data)\n",
    "model_recommendation_df.style.set_properties(**{\n",
    "    'white-space': 'pre-wrap',\n",
    "    'word-wrap': 'break-word',\n",
    "    'max-width': '300px'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c93131-cd6c-472a-bddb-5df8516ff0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
