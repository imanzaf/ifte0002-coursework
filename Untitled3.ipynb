{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whFbqLJ-V8rO",
        "outputId": "1d18b46f-5632-4cec-c65f-435c0a8da9a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective:\n",
        "\n",
        "The objective of Return Model 1 is to predict the expected return on individual Lending Club loans using borrower and loan attributes known at the time of issuance. This supports the construction of investment portfolios focused on maximizing return, as required by the coursework.\n",
        "\n",
        "Return Metric Definition:\n",
        "\n",
        "The chosen metric, custom_return_1, is calculated as (total_pymnt−loan_amnt)/loan_amnt(total_pymnt−loan_amnt)/loan_amnt, capturing the net percentage gain or loss on a loan.\n",
        "\n"
      ],
      "metadata": {
        "id": "Pl2igL69xBHh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VeqyZY75bQbe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/lending_club_dataset.pickle\"\n",
        "\n",
        "\n",
        "data = pd.read_pickle(path)\n",
        "df = data[0]\n",
        "\n",
        "# Return metric\n",
        "df[\"custom_return_1\"] = (df[\"total_pymnt\"] - df[\"loan_amnt\"]) / df[\"loan_amnt\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bCSPSxBxbsNQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define features\n",
        "numerical = [\"loan_amnt\", \"funded_amnt\", \"installment\", \"int_rate\", \"annual_inc\", \"loan_length\", \"term_num\"]\n",
        "categorical = [\"home_ownership\", \"grade\", \"emp_length\"]\n",
        "features = numerical + categorical\n",
        "target = \"custom_return_1\"\n",
        "\n",
        "# Split\n",
        "df_sample = df.sample(n=50000, random_state=42)\n",
        "X = df_sample[features]\n",
        "y = df_sample[\"custom_return_1\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Selection:\n",
        "\n",
        "Features were selected based on their economic relevance to loan performance and their availability at the loan’s origination. Numerical variables included loan_amnt, funded_amnt, installment, int_rate, annual_inc, loan_length, and term_num, while categorical features included home_ownership, grade, and emp_length.\n"
      ],
      "metadata": {
        "id": "16WPORVQxR6R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ECGwImV-bvuS"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    (\"num\", StandardScaler(), numerical),\n",
        "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Processing:\n",
        "\n",
        "To prepare the dataset for model training, we applied systematic preprocessing to both numerical and categorical features using a scikit-learn ColumnTransformer. All numerical variables (loan_amnt, funded_amnt, installment, int_rate, annual_inc, loan_length, and term_num) were standardized using StandardScaler to ensure zero mean and unit variance.\n",
        "\n",
        "This step is particularly important for linear models like Lasso, which are sensitive to the scale of input features. Categorical variables (home_ownership, grade, emp_length) were transformed using OneHotEncoder, allowing models to handle non-numeric categories effectively. To ensure consistent and reproducible preprocessing, these transformations were embedded within a scikit-learn Pipeline, which combines preprocessing and model training into a single unified workflow.\n",
        "\n"
      ],
      "metadata": {
        "id": "tnQoQzljxYbr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ra-f0_F_b1YY"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "models = {\n",
        "    \"Lasso\": Lasso(alpha=0.01, max_iter=10000),\n",
        "    \"RandomForest\": RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42),\n",
        "    \"XGBoost\": XGBRegressor(n_estimators=50, max_depth=6, learning_rate=0.1, random_state=42)\n",
        "}\n",
        "\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    pipe = Pipeline([\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"model\", model)\n",
        "    ])\n",
        "    pipe.fit(X_train, y_train)\n",
        "    preds = pipe.predict(X_test)\n",
        "\n",
        "    results[name] = {\n",
        "        \"MSE\": mean_squared_error(y_test, preds),\n",
        "        \"R2\": r2_score(y_test, preds)\n",
        "    }\n",
        "\n",
        "# Random Guessing Baseline\n",
        "random_preds = shuffle(y_test.copy(), random_state=42)\n",
        "results[\"RandomGuessing\"] = {\n",
        "    \"MSE\": mean_squared_error(y_test, random_preds),\n",
        "    \"R2\": r2_score(y_test, random_preds)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train/Test Split:\n",
        "\n",
        "The dataset was split into an 80% training set and 20% testing set using train_test_split. This ensures that models are evaluated on unseen data to assess generalization performance, in line with standard evaluation methods discussed in lectures.\n",
        "\n",
        "Model Selection:\n",
        "\n",
        "Three models were trained to predict loan return: Lasso Regression, Random Forest Regressor, and XGBoost Regressor. Lasso provides a simple linear benchmark with embedded feature selection. Random Forest uses bagging to reduce variance, while XGBoost applies boosting for high predictive performance. All models were implemented using scikit-learn pipelines to streamline preprocessing and training and was compared against a random guessing strategy by shuffling test labels.\n"
      ],
      "metadata": {
        "id": "P-yqKFPwxreT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, metrics in results.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"  MSE: {metrics['MSE']:.4f}\")\n",
        "    print(f\"  R²:  {metrics['R2']:.4f}\\\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P612xzaZhgEM",
        "outputId": "a78ef638-aadd-4e8f-ca01-4edd63f8ef67"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Lasso\n",
            "  MSE: 0.0642\n",
            "  R²:  0.2221\\n\n",
            "Model: RandomForest\n",
            "  MSE: 0.0601\n",
            "  R²:  0.2723\\n\n",
            "Model: XGBoost\n",
            "  MSE: 0.0596\n",
            "  R²:  0.2783\\n\n",
            "Model: RandomGuessing\n",
            "  MSE: 0.1676\n",
            "  R²:  -1.0288\\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample Size:\n",
        "\n",
        "To balance computational efficiency with predictive power, a random subset of 50,000 loans was used for model training. This sample size captures representative patterns in the data while remaining tractable within the Google Colab environment\n"
      ],
      "metadata": {
        "id": "cyAgPfL1zmKE"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}